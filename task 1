# === Import Libraries ===
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import os

# === Step 1: Extract Data ===
# Update this path to your uploaded file name
file_path = '/mnt/data/file-P1Shs5vYeSgdFzpuiHHzav'

# Load the dataset
df = pd.read_csv(file_path)
print("Initial Data Preview:")
print(df.head())

# === Step 2: Data Cleaning (optional) ===
# Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

# Drop rows with missing values (or fill them)
df = df.dropna()

# === Step 3: Transform Data ===
# Convert categorical columns (if any)
df_encoded = pd.get_dummies(df)

# Normalize the numeric features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df_encoded)

# Create final DataFrame
df_transformed = pd.DataFrame(scaled_features, columns=df_encoded.columns)

# === Step 4: Load Data (Split for ML) ===
X = df_transformed.iloc[:, :-1]
y = df_transformed.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nData Pipeline Completed Successfully.")
print("Training Set Shape:", X_train.shape)
print("Test Set Shape:", X_test.shape)
